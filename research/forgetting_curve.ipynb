{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between Exp and Pow forgetting curves\n",
    "\n",
    "[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/open-spaced-repetition/fsrs4anki/blob/Expt/new-baseline/research/forgetting_curve.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some settings that you need to replace before running this optimizer.\n",
    "\n",
    "filename = \"../collection-2022-09-18@13-21-58.colpkg\"\n",
    "# If you upload deck file, replace it with your deck filename. E.g., ALL__Learning.apkg\n",
    "# If you upload collection file, replace it with your colpgk filename. E.g., collection-2022-09-18@13-21-58.colpkg\n",
    "\n",
    "# Replace it with your timezone. I'm in China, so I use Asia/Shanghai.\n",
    "# You can find your timezone here: https://gist.github.com/heyalexej/8bf688fd67d7199be4a1682b3eec7568\n",
    "timezone = 'Asia/Shanghai'\n",
    "\n",
    "# Replace it with your Anki's setting in Preferences -> Scheduling.\n",
    "next_day_starts_at = 4\n",
    "\n",
    "# Replace it if you don't want the optimizer to use the review logs before a specific date.\n",
    "revlog_start_date = \"2006-10-05\"\n",
    "\n",
    "# Set it to True if you don't want the optimizer to use the review logs from suspended cards.\n",
    "filter_out_suspended_cards = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import sqlite3\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import accumulate\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deck file extracted successfully!\n",
      "revlog.csv saved.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Step 1\"\"\"\n",
    "# Extract the collection file or deck file to get the .anki21 database.\n",
    "with zipfile.ZipFile(f'{filename}', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n",
    "    print(\"Deck file extracted successfully!\")\n",
    "\n",
    "\"\"\"Step 2\"\"\"\n",
    "if os.path.isfile(\"collection.anki21b\"):\n",
    "    os.remove(\"collection.anki21b\")\n",
    "    raise Exception(\n",
    "        \"Please export the file with `support older Anki versions` if you use the latest version of Anki.\")\n",
    "elif os.path.isfile(\"collection.anki21\"):\n",
    "    con = sqlite3.connect(\"collection.anki21\")\n",
    "elif os.path.isfile(\"collection.anki2\"):\n",
    "    con = sqlite3.connect(\"collection.anki2\")\n",
    "else:\n",
    "    raise Exception(\"Collection not exist!\")\n",
    "cur = con.cursor()\n",
    "res = cur.execute(f\"\"\"\n",
    "SELECT *\n",
    "FROM revlog\n",
    "WHERE cid IN (\n",
    "    SELECT id\n",
    "    FROM cards\n",
    "    {\"WHERE queue != -1\" if filter_out_suspended_cards else \"\"}\n",
    ")\n",
    "\"\"\"\n",
    ")\n",
    "revlog = res.fetchall()\n",
    "if len(revlog) == 0:\n",
    "    raise Exception(\"No review log found!\")\n",
    "df = pd.DataFrame(revlog)\n",
    "df.columns = ['id', 'cid', 'usn', 'r', 'ivl', 'last_lvl', 'factor', 'time', 'type']\n",
    "df = df[(df['cid'] <= time.time() * 1000) &\n",
    "        (df['id'] <= time.time() * 1000)].copy()\n",
    "\n",
    "df_set_due_date = df[(df['type'] == 4) & (df['ivl'] > 0)]\n",
    "df.drop(df_set_due_date.index, inplace=True)\n",
    "\n",
    "df['create_date'] = pd.to_datetime(df['cid'] // 1000, unit='s')\n",
    "df['create_date'] = df['create_date'].dt.tz_localize('UTC').dt.tz_convert(timezone)\n",
    "df['review_date'] = pd.to_datetime(df['id'] // 1000, unit='s')\n",
    "df['review_date'] = df['review_date'].dt.tz_localize('UTC').dt.tz_convert(timezone)\n",
    "df.drop(df[df['review_date'].dt.year < 2006].index, inplace=True)\n",
    "df.sort_values(by=['cid', 'id'], inplace=True, ignore_index=True)\n",
    "\n",
    "df['is_learn_start'] = (df['type'] == 0) & (df['type'].shift() != 0)\n",
    "df['sequence_group'] = df['is_learn_start'].cumsum()\n",
    "last_learn_start = df[df['is_learn_start']].groupby('cid')['sequence_group'].last()\n",
    "df['last_learn_start'] = df['cid'].map(last_learn_start).fillna(0).astype(int)\n",
    "df['mask'] = df['last_learn_start'] <= df['sequence_group']\n",
    "df = df[df['mask'] == True].copy()\n",
    "df.drop(columns=['is_learn_start', 'sequence_group', 'last_learn_start', 'mask'], inplace=True)\n",
    "df = df[(df['type'] != 4)].copy()\n",
    "\n",
    "type_sequence = np.array(df['type'])\n",
    "time_sequence = np.array(df['time'])\n",
    "df.to_csv(\"revlog.csv\", index=False)\n",
    "print(\"revlog.csv saved.\")\n",
    "\n",
    "df = df[(df['type'] != 3) | (df['factor'] != 0)].copy()\n",
    "df['real_days'] = df['review_date'] - timedelta(hours=int(next_day_starts_at))\n",
    "df['real_days'] = pd.DatetimeIndex(df['real_days'].dt.floor('D', ambiguous='infer', nonexistent='shift_forward')).to_julian_date()\n",
    "df.drop_duplicates(['cid', 'real_days'], keep='first', inplace=True)\n",
    "df['delta_t'] = df.real_days.diff()\n",
    "df.dropna(inplace=True)\n",
    "df['i'] = df.groupby('cid').cumcount() + 1\n",
    "df.loc[df['i'] == 1, 'delta_t'] = 0\n",
    "df = df.groupby('cid').filter(lambda group: group['type'].iloc[0] == 0)\n",
    "df['prev_type'] = df.groupby('cid')['type'].shift(1).fillna(0).astype(int)\n",
    "df['helper'] = ((df['type'] == 0) & ((df['prev_type'] == 1) | (df['prev_type'] == 2)) & (df['i'] > 1)).astype(int)\n",
    "df['helper'] = df.groupby('cid')['helper'].cumsum()\n",
    "df = df[df['helper'] == 0]\n",
    "del df['prev_type']\n",
    "del df['helper']\n",
    "\n",
    "def cum_concat(x):\n",
    "    return list(accumulate(x))\n",
    "\n",
    "t_history = df.groupby('cid', group_keys=False)['delta_t'].apply(lambda x: cum_concat([[int(i)] for i in x]))\n",
    "df['t_history']=[','.join(map(str, item[:-1])) for sublist in t_history for item in sublist]\n",
    "r_history = df.groupby('cid', group_keys=False)['r'].apply(lambda x: cum_concat([[i] for i in x]))\n",
    "df['r_history']=[','.join(map(str, item[:-1])) for sublist in r_history for item in sublist]\n",
    "df = df.groupby('cid').filter(lambda group: group['id'].min() > time.mktime(datetime.strptime(revlog_start_date, \"%Y-%m-%d\").timetuple()) * 1000)\n",
    "df['y'] = df['r'].map(lambda x: {1: 0, 2: 1, 3: 1, 4: 1}[x])\n",
    "df.to_csv('revlog_history.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_t</th>\n",
       "      <th>i</th>\n",
       "      <th>t_history</th>\n",
       "      <th>r_history</th>\n",
       "      <th>retention</th>\n",
       "      <th>total_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893817</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38515</th>\n",
       "      <td>43.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0,1,4,12</td>\n",
       "      <td>4,4,4,4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>139.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0,4,12,38</td>\n",
       "      <td>4,4,4,4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38516</th>\n",
       "      <td>122.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0,1,4,12,43</td>\n",
       "      <td>4,4,4,4,3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7969</th>\n",
       "      <td>410.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0,4,12,38,139</td>\n",
       "      <td>4,4,4,4,3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38517</th>\n",
       "      <td>377.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0,1,4,12,43,122</td>\n",
       "      <td>4,4,4,4,3,3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56883 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       delta_t  i        t_history    r_history  retention  total_cnt\n",
       "275        1.0  2                0            1   0.893817       1488\n",
       "5111       2.0  2                0            1   0.872222        360\n",
       "218        3.0  2                0            1   0.790909        110\n",
       "345        4.0  2                0            1   0.800000         50\n",
       "396        5.0  2                0            1   0.707317         41\n",
       "...        ... ..              ...          ...        ...        ...\n",
       "38515     43.0  5         0,1,4,12      4,4,4,4   1.000000          1\n",
       "7968     139.0  5        0,4,12,38      4,4,4,4   1.000000          1\n",
       "38516    122.0  6      0,1,4,12,43    4,4,4,4,3   1.000000          1\n",
       "7969     410.0  6    0,4,12,38,139    4,4,4,4,3   1.000000          1\n",
       "38517    377.0  7  0,1,4,12,43,122  4,4,4,4,3,3   1.000000          1\n",
       "\n",
       "[56883 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "df_analysis = df[(df['i'] > 1) & (df['delta_t'] > 0) & (df['t_history'].str.count(',0') == 0)].copy()\n",
    "\n",
    "\n",
    "df_analysis['retention'] = df_analysis.groupby(by=['r_history', 't_history', 'delta_t'], group_keys=False)['y'].transform('mean')\n",
    "df_analysis['total_cnt'] = df_analysis.groupby(by=['r_history', 't_history', 'delta_t'], group_keys=False)['id'].transform('count')\n",
    "df_analysis.drop(columns=['id', 'cid', 'usn', 'r', 'ivl', 'last_lvl', 'factor', 'time', 'type', 'create_date', 'review_date', 'real_days', 'y'], inplace=True)\n",
    "df_analysis.drop_duplicates(inplace=True)\n",
    "df_analysis.sort_values(by=['r_history', 't_history', 'delta_t'], inplace=True)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_curve(delta_t, S):\n",
    "    return 0.9 ** (delta_t / S)\n",
    "\n",
    "def reverse_exp_curve(delta_t, R):\n",
    "    return np.log(0.9) / np.log(R) * delta_t\n",
    "\n",
    "def pow_curve(delta_t, S):\n",
    "    return (1 + delta_t / (9 * S)) ** -1\n",
    "\n",
    "def reverse_pow_curve(delta_t, R):\n",
    "    return delta_t / 9 / (1 / R - 1)\n",
    "\n",
    "def fit_stability(delta_t, recall, cnt, curve_func, reverse_curve_func):\n",
    "    try:\n",
    "        params, _ = curve_fit(curve_func, delta_t, recall, sigma=1/np.sqrt(cnt), bounds=((0.1), (3650)))\n",
    "        return params[0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return reverse_curve_func(delta_t.values, recall.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1929ef1718224878a87bca5e87fd566c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_exp_stability = df_analysis.groupby(by=['r_history', 't_history']).progress_apply(lambda group: fit_stability(group['delta_t'], group['retention'], group['total_cnt'], exp_curve, reverse_exp_curve)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff1194febca4bdcb228af6e70259be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pow_stability = df_analysis.groupby(by=['r_history', 't_history']).progress_apply(lambda group: fit_stability(group['delta_t'], group['retention'], group['total_cnt'], pow_curve, reverse_pow_curve)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.merge(df_analysis, df_exp_stability, on=['r_history', 't_history'], how='left').rename(columns={0: 'exp_stability'})\n",
    "df_test = pd.merge(tmp, df_pow_stability, on=['r_history', 't_history'], how='left').rename(columns={0: 'pow_stability'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['exp_recall'] = exp_curve(df_test['delta_t'], df_test['exp_stability'])\n",
    "df_test['pow_recall'] = pow_curve(df_test['delta_t'], df_test['pow_stability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_rmse: 0.08470186301992909\n",
      "pow_rmse: 0.09005832046244422\n"
     ]
    }
   ],
   "source": [
    "exp_rmse = mean_squared_error(df_test['retention'], df_test['exp_recall'], sample_weight=df_test['total_cnt'], squared=False)\n",
    "pow_rmse = mean_squared_error(df_test['retention'], df_test['pow_recall'], sample_weight=df_test['total_cnt'], squared=False)\n",
    "print(f\"exp_rmse: {exp_rmse}\")\n",
    "print(f\"pow_rmse: {pow_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first review exp_rmse: 0.027728287577305333\n",
      "first review pow_rmse: 0.025822027313503877\n"
     ]
    }
   ],
   "source": [
    "first_review = df_test[df_test['i'] == 2].copy()\n",
    "exp_rmse = mean_squared_error(first_review['retention'], first_review['exp_recall'], sample_weight=first_review['total_cnt'], squared=False)\n",
    "pow_rmse = mean_squared_error(first_review['retention'], first_review['pow_recall'], sample_weight=first_review['total_cnt'], squared=False)\n",
    "print(f\"first review exp_rmse: {exp_rmse}\")\n",
    "print(f\"first review pow_rmse: {pow_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rest reviews exp_rmse: 0.08928613755836967\n",
      "rest reviews pow_rmse: 0.09506514574203066\n"
     ]
    }
   ],
   "source": [
    "rest_reviews = df_test[df_test['i'] > 2].copy()\n",
    "exp_rmse = mean_squared_error(rest_reviews['retention'], rest_reviews['exp_recall'], sample_weight=rest_reviews['total_cnt'], squared=False)\n",
    "pow_rmse = mean_squared_error(rest_reviews['retention'], rest_reviews['pow_recall'], sample_weight=rest_reviews['total_cnt'], squared=False)\n",
    "print(f\"rest reviews exp_rmse: {exp_rmse}\")\n",
    "print(f\"rest reviews pow_rmse: {pow_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsrs4anki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
